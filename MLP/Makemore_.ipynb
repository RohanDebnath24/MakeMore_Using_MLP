{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", \"r\").read().split()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(''.join(words))))\n",
    "stoi = {c:i+1 for i , c in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos={i:s for s,i in stoi.items()}\n",
    "print(stoi)\n",
    "print(itos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "[[0, 0, 0]] [5]\n",
      "... ----> e\n",
      "[[0, 0, 0], [0, 0, 5]] [5, 13]\n",
      "..e ----> m\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13]] [5, 13, 13]\n",
      ".em ----> m\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13]] [5, 13, 13, 1]\n",
      "emm ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1]] [5, 13, 13, 1, 0]\n",
      "mma ----> .\n",
      "olivia\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0]] [5, 13, 13, 1, 0, 15]\n",
      "... ----> o\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15]] [5, 13, 13, 1, 0, 15, 12]\n",
      "..o ----> l\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12]] [5, 13, 13, 1, 0, 15, 12, 9]\n",
      ".ol ----> i\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9]] [5, 13, 13, 1, 0, 15, 12, 9, 22]\n",
      "oli ----> v\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9]\n",
      "liv ----> i\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1]\n",
      "ivi ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0]\n",
      "via ----> .\n",
      "ava\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1]\n",
      "... ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22]\n",
      "..a ----> v\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1]\n",
      ".av ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0]\n",
      "ava ----> .\n",
      "isabella\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9]\n",
      "... ----> i\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19]\n",
      "..i ----> s\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1]\n",
      ".is ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2]\n",
      "isa ----> b\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5]\n",
      "sab ----> e\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12]\n",
      "abe ----> l\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12]\n",
      "bel ----> l\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1]\n",
      "ell ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0]\n",
      "lla ----> .\n",
      "sophia\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19]\n",
      "... ----> s\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19, 15]\n",
      "..s ----> o\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19], [0, 19, 15]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19, 15, 16]\n",
      ".so ----> p\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19], [0, 19, 15], [19, 15, 16]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19, 15, 16, 8]\n",
      "sop ----> h\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19], [0, 19, 15], [19, 15, 16], [15, 16, 8]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19, 15, 16, 8, 9]\n",
      "oph ----> i\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19], [0, 19, 15], [19, 15, 16], [15, 16, 8], [16, 8, 9]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19, 15, 16, 8, 9, 1]\n",
      "phi ----> a\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19], [0, 19, 15], [19, 15, 16], [15, 16, 8], [16, 8, 9], [8, 9, 1]] [5, 13, 13, 1, 0, 15, 12, 9, 22, 9, 1, 0, 1, 22, 1, 0, 9, 19, 1, 2, 5, 12, 12, 1, 0, 19, 15, 16, 8, 9, 1, 0]\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length: how many characters to take to predict the next character\n",
    "X,Y=[],[]\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context=[0]*block_size # Creates an initial context of [0, 0, 0]. This serves as the starting context before actual characters from the word are added. Assuming 0 is a special padding token\n",
    "    for ch in w + '.':# Iterate through each character in the word plus a stopping character ('.')\n",
    "        ix =stoi[ch] # Convert character to its integer index using a predefined `stoi` dictionary\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(X,Y)\n",
    "        print(''.join(itos[i] for i in context),'---->',itos[ix])# Print the mapping from context to predicted character\n",
    "        context=context[1:]+[ix] # Shift the context window by removing the first character and appending the new one\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 15],\n",
       "         [ 0, 15, 12],\n",
       "         [15, 12,  9],\n",
       "         [12,  9, 22],\n",
       "         [ 9, 22,  9],\n",
       "         [22,  9,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1, 22],\n",
       "         [ 1, 22,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  9],\n",
       "         [ 0,  9, 19],\n",
       "         [ 9, 19,  1],\n",
       "         [19,  1,  2],\n",
       "         [ 1,  2,  5],\n",
       "         [ 2,  5, 12],\n",
       "         [ 5, 12, 12],\n",
       "         [12, 12,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 19],\n",
       "         [ 0, 19, 15],\n",
       "         [19, 15, 16],\n",
       "         [15, 16,  8],\n",
       "         [16,  8,  9],\n",
       "         [ 8,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "C= torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F.one_hot(torch.tensor(5),num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb=C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=torch.randn(6,100)\n",
    "b1=torch.randn(100)\n",
    "emb @ W1 + b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(emb,start_dim=1,end_dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0079, -0.0464, -1.6455],\n",
      "        [-0.4411,  1.0999,  0.4642]])\n",
      "tensor([[ 0.0079, -0.0464, -1.6455],\n",
      "        [-0.4411,  1.0999,  0.4642],\n",
      "        [ 0.0079, -0.0464, -1.6455],\n",
      "        [-0.4411,  1.0999,  0.4642],\n",
      "        [ 0.0079, -0.0464, -1.6455],\n",
      "        [-0.4411,  1.0999,  0.4642]])\n",
      "tensor([[ 0.0079, -0.0464, -1.6455,  0.0079, -0.0464, -1.6455],\n",
      "        [-0.4411,  1.0999,  0.4642, -0.4411,  1.0999,  0.4642]])\n"
     ]
    }
   ],
   "source": [
    "# Function of torch.cat\n",
    "'''x = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(torch.cat((x,x,x),0))\n",
    "print(torch.cat((x,x),1))\n",
    "#print(torch.cat((x,x,x),2))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [ 0.0546,  2.4548]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [ 0.0546,  2.4548],\n",
       "         [-0.1514, -1.2279]],\n",
       "\n",
       "        [[ 0.0546,  2.4548],\n",
       "         [-0.1514, -1.2279],\n",
       "         [-0.1514, -1.2279]],\n",
       "\n",
       "        [[-0.1514, -1.2279],\n",
       "         [-0.1514, -1.2279],\n",
       "         [ 0.8285,  1.4391]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-0.5391,  0.4790]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-0.5391,  0.4790],\n",
       "         [ 0.1167, -0.8259]],\n",
       "\n",
       "        [[-0.5391,  0.4790],\n",
       "         [ 0.1167, -0.8259],\n",
       "         [-0.7695,  0.2704]],\n",
       "\n",
       "        [[ 0.1167, -0.8259],\n",
       "         [-0.7695,  0.2704],\n",
       "         [-0.1459, -1.3000]],\n",
       "\n",
       "        [[-0.7695,  0.2704],\n",
       "         [-0.1459, -1.3000],\n",
       "         [-0.7695,  0.2704]],\n",
       "\n",
       "        [[-0.1459, -1.3000],\n",
       "         [-0.7695,  0.2704],\n",
       "         [ 0.8285,  1.4391]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [ 0.8285,  1.4391]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [ 0.8285,  1.4391],\n",
       "         [-0.1459, -1.3000]],\n",
       "\n",
       "        [[ 0.8285,  1.4391],\n",
       "         [-0.1459, -1.3000],\n",
       "         [ 0.8285,  1.4391]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-0.7695,  0.2704]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-0.7695,  0.2704],\n",
       "         [ 3.2712,  0.4613]],\n",
       "\n",
       "        [[-0.7695,  0.2704],\n",
       "         [ 3.2712,  0.4613],\n",
       "         [ 0.8285,  1.4391]],\n",
       "\n",
       "        [[ 3.2712,  0.4613],\n",
       "         [ 0.8285,  1.4391],\n",
       "         [ 0.0097, -0.8480]],\n",
       "\n",
       "        [[ 0.8285,  1.4391],\n",
       "         [ 0.0097, -0.8480],\n",
       "         [ 0.0546,  2.4548]],\n",
       "\n",
       "        [[ 0.0097, -0.8480],\n",
       "         [ 0.0546,  2.4548],\n",
       "         [ 0.1167, -0.8259]],\n",
       "\n",
       "        [[ 0.0546,  2.4548],\n",
       "         [ 0.1167, -0.8259],\n",
       "         [ 0.1167, -0.8259]],\n",
       "\n",
       "        [[ 0.1167, -0.8259],\n",
       "         [ 0.1167, -0.8259],\n",
       "         [ 0.8285,  1.4391]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [-1.3949,  0.5145],\n",
       "         [ 3.2712,  0.4613]],\n",
       "\n",
       "        [[-1.3949,  0.5145],\n",
       "         [ 3.2712,  0.4613],\n",
       "         [-0.5391,  0.4790]],\n",
       "\n",
       "        [[ 3.2712,  0.4613],\n",
       "         [-0.5391,  0.4790],\n",
       "         [ 0.1868,  1.0233]],\n",
       "\n",
       "        [[-0.5391,  0.4790],\n",
       "         [ 0.1868,  1.0233],\n",
       "         [ 0.3848, -0.4572]],\n",
       "\n",
       "        [[ 0.1868,  1.0233],\n",
       "         [ 0.3848, -0.4572],\n",
       "         [-0.7695,  0.2704]],\n",
       "\n",
       "        [[ 0.3848, -0.4572],\n",
       "         [-0.7695,  0.2704],\n",
       "         [ 0.8285,  1.4391]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we need to find a way to take the embedding first character of each trigram and form an array that is do this:\n",
    " [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
    "\n",
    " [ 0.0546,  2.4548, -0.1514, -1.2279, -1.3949,  0.5145]\n",
    "  \n",
    " etc \n",
    " \n",
    " because the nueral layer is of size (6,100) and the embedding is of size(32,3,2) some how we have to make it (32,6) feed it to the neural layer so to do that there are three ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(emb,start_dim=1,end_dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take out the first dimension of the each embedding of a trigram by using unbinding\n",
    "torch.cat(torch.unbind(emb,1),1)#inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145,  0.0546,  2.4548],\n",
       "        [-1.3949,  0.5145,  0.0546,  2.4548, -0.1514, -1.2279],\n",
       "        [ 0.0546,  2.4548, -0.1514, -1.2279, -0.1514, -1.2279],\n",
       "        [-0.1514, -1.2279, -0.1514, -1.2279,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -0.5391,  0.4790],\n",
       "        [-1.3949,  0.5145, -0.5391,  0.4790,  0.1167, -0.8259],\n",
       "        [-0.5391,  0.4790,  0.1167, -0.8259, -0.7695,  0.2704],\n",
       "        [ 0.1167, -0.8259, -0.7695,  0.2704, -0.1459, -1.3000],\n",
       "        [-0.7695,  0.2704, -0.1459, -1.3000, -0.7695,  0.2704],\n",
       "        [-0.1459, -1.3000, -0.7695,  0.2704,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145,  0.8285,  1.4391, -0.1459, -1.3000],\n",
       "        [ 0.8285,  1.4391, -0.1459, -1.3000,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -0.7695,  0.2704],\n",
       "        [-1.3949,  0.5145, -0.7695,  0.2704,  3.2712,  0.4613],\n",
       "        [-0.7695,  0.2704,  3.2712,  0.4613,  0.8285,  1.4391],\n",
       "        [ 3.2712,  0.4613,  0.8285,  1.4391,  0.0097, -0.8480],\n",
       "        [ 0.8285,  1.4391,  0.0097, -0.8480,  0.0546,  2.4548],\n",
       "        [ 0.0097, -0.8480,  0.0546,  2.4548,  0.1167, -0.8259],\n",
       "        [ 0.0546,  2.4548,  0.1167, -0.8259,  0.1167, -0.8259],\n",
       "        [ 0.1167, -0.8259,  0.1167, -0.8259,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145,  3.2712,  0.4613],\n",
       "        [-1.3949,  0.5145,  3.2712,  0.4613, -0.5391,  0.4790],\n",
       "        [ 3.2712,  0.4613, -0.5391,  0.4790,  0.1868,  1.0233],\n",
       "        [-0.5391,  0.4790,  0.1868,  1.0233,  0.3848, -0.4572],\n",
       "        [ 0.1868,  1.0233,  0.3848, -0.4572, -0.7695,  0.2704],\n",
       "        [ 0.3848, -0.4572, -0.7695,  0.2704,  0.8285,  1.4391]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:,0,:],emb[:,1,:],emb[:,2,:]],dim=1)# unefficient aas creates new tensor to concatenate the values because there is no way to concatenate with using views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0377, -0.0330],\n",
      "         [-1.5238, -1.3840],\n",
      "         [ 0.9075,  1.4327]],\n",
      "\n",
      "        [[ 0.0604, -0.8923],\n",
      "         [-0.3241,  1.6402],\n",
      "         [-0.3417,  1.2738]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0377, -1.5238,  0.9075],\n",
       "         [ 0.0604, -0.3241, -0.3417]]),\n",
       " tensor([[-0.0330, -1.3840,  1.4327],\n",
       "         [-0.8923,  1.6402,  1.2738]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Working of torch.unbind\n",
    "a=torch.randn(2,3,2)\n",
    "print(a)\n",
    "torch.unbind(a,dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(2,9)\n",
    "a.view(2,3,3)\n",
    "a.view(9,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_13376\\967240405.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Why does this work ?\n",
    "a.storage()# Number always as a one dimension vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145,  0.0546,  2.4548],\n",
       "        [-1.3949,  0.5145,  0.0546,  2.4548, -0.1514, -1.2279],\n",
       "        [ 0.0546,  2.4548, -0.1514, -1.2279, -0.1514, -1.2279],\n",
       "        [-0.1514, -1.2279, -0.1514, -1.2279,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -0.5391,  0.4790],\n",
       "        [-1.3949,  0.5145, -0.5391,  0.4790,  0.1167, -0.8259],\n",
       "        [-0.5391,  0.4790,  0.1167, -0.8259, -0.7695,  0.2704],\n",
       "        [ 0.1167, -0.8259, -0.7695,  0.2704, -0.1459, -1.3000],\n",
       "        [-0.7695,  0.2704, -0.1459, -1.3000, -0.7695,  0.2704],\n",
       "        [-0.1459, -1.3000, -0.7695,  0.2704,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145,  0.8285,  1.4391, -0.1459, -1.3000],\n",
       "        [ 0.8285,  1.4391, -0.1459, -1.3000,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -0.7695,  0.2704],\n",
       "        [-1.3949,  0.5145, -0.7695,  0.2704,  3.2712,  0.4613],\n",
       "        [-0.7695,  0.2704,  3.2712,  0.4613,  0.8285,  1.4391],\n",
       "        [ 3.2712,  0.4613,  0.8285,  1.4391,  0.0097, -0.8480],\n",
       "        [ 0.8285,  1.4391,  0.0097, -0.8480,  0.0546,  2.4548],\n",
       "        [ 0.0097, -0.8480,  0.0546,  2.4548,  0.1167, -0.8259],\n",
       "        [ 0.0546,  2.4548,  0.1167, -0.8259,  0.1167, -0.8259],\n",
       "        [ 0.1167, -0.8259,  0.1167, -0.8259,  0.8285,  1.4391],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145, -1.3949,  0.5145],\n",
       "        [-1.3949,  0.5145, -1.3949,  0.5145,  3.2712,  0.4613],\n",
       "        [-1.3949,  0.5145,  3.2712,  0.4613, -0.5391,  0.4790],\n",
       "        [ 3.2712,  0.4613, -0.5391,  0.4790,  0.1868,  1.0233],\n",
       "        [-0.5391,  0.4790,  0.1868,  1.0233,  0.3848, -0.4572],\n",
       "        [ 0.1868,  1.0233,  0.3848, -0.4572, -0.7695,  0.2704],\n",
       "        [ 0.3848, -0.4572, -0.7695,  0.2704,  0.8285,  1.4391]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=torch.randn(6,100)\n",
    "b1=torch.randn(100)\n",
    "h=torch.tanh(emb.view(-1,6) @ W1+b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.9995, -0.0350,  ..., -0.9982, -0.9996, -0.9998],\n",
       "        [-1.0000, -0.9614, -0.4546,  ..., -0.9965, -1.0000, -1.0000],\n",
       "        [ 0.9987, -0.9997, -0.4110,  ..., -0.9751, -0.9949,  0.5634],\n",
       "        ...,\n",
       "        [ 0.9969, -0.9724, -0.1110,  ..., -0.3865, -0.9794,  0.3704],\n",
       "        [ 0.0831, -0.9881,  0.3437,  ...,  0.2040, -0.9669, -0.5715],\n",
       "        [-0.9530,  0.9241,  0.3901,  ..., -0.9862, -0.9713, -0.9972]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h# nos between -1 and 1 because of tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2=torch.randn(100,27)\n",
    "b2=torch.randn(27)\n",
    "logits= h @ W2+b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=logits.exp()\n",
    "probs=counts/counts.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.3648)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll=-probs[torch.arange(32),Y].log().mean()\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
